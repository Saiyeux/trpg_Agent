"""
é…ç½®ç®¡ç†æ¨¡å—

è´Ÿè´£TRPGç³»ç»Ÿçš„é…ç½®æ–‡ä»¶ç®¡ç†ï¼Œæ”¯æŒå¤šç§AIåç«¯å’Œçµæ´»çš„å‚æ•°é…ç½®ã€‚
æä¾›äº¤äº’å¼é…ç½®å’Œé…ç½®éªŒè¯åŠŸèƒ½ã€‚

ä¸»è¦åŠŸèƒ½:
- é…ç½®æ–‡ä»¶åŠ è½½å’Œä¿å­˜
- å¤šAIåç«¯é…ç½®ç®¡ç†
- äº¤äº’å¼é…ç½®è®¾ç½®
- é…ç½®éªŒè¯å’Œé»˜è®¤å€¼
"""

import json
import os
from typing import Dict, Any, List, Optional
from ..client.model_client import APIType


class ConfigManager:
    """
    TRPGç³»ç»Ÿé…ç½®ç®¡ç†å™¨
    
    ç®¡ç†ç³»ç»Ÿçš„æ‰€æœ‰é…ç½®é€‰é¡¹ï¼ŒåŒ…æ‹¬AIåç«¯è®¾ç½®ã€æ¸¸æˆå‚æ•°ã€æ—¥å¿—é…ç½®ç­‰ã€‚
    æ”¯æŒé…ç½®æ–‡ä»¶çš„åŠ è½½ã€ä¿å­˜å’Œäº¤äº’å¼è®¾ç½®ã€‚
    """
    
    def __init__(self, config_file: str = "config/game_config.json"):
        """
        åˆå§‹åŒ–é…ç½®ç®¡ç†å™¨
        
        Args:
            config_file: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.config_file = config_file
        self.config = self._load_config()
        
    def get_api_type(self) -> APIType:
        """
        è·å–å½“å‰é…ç½®çš„APIç±»å‹
        
        Returns:
            APIç±»å‹æšä¸¾
            
        è°ƒç”¨æ—¶æœº: åˆå§‹åŒ–AIå®¢æˆ·ç«¯æ—¶
        """
        api_type_str = self.config["api"]["type"]
        return APIType.OLLAMA if api_type_str == "ollama" else APIType.LM_STUDIO
        
    def get_api_config(self) -> Dict[str, Any]:
        """
        è·å–å½“å‰APIçš„é…ç½®ä¿¡æ¯
        
        Returns:
            åŒ…å«APIé…ç½®çš„å­—å…¸
            
        è°ƒç”¨æ—¶æœº: åˆå§‹åŒ–AIå®¢æˆ·ç«¯æ—¶
        """
        api_type = self.get_api_type()
        config_key = api_type.value
        api_config = self.config[config_key].copy()
        
        # å¯¹äºLM Studioï¼Œæ¨¡å‹åç§°è®¾ä¸ºå›ºå®šå€¼ï¼Œå› ä¸ºå®ƒä½¿ç”¨å½“å‰åŠ è½½çš„æ¨¡å‹
        if api_type == APIType.LM_STUDIO:
            api_config["model"] = "current_loaded_model"
            
        return api_config
        
    def get_game_config(self) -> Dict[str, Any]:
        """
        è·å–æ¸¸æˆç›¸å…³é…ç½®
        
        Returns:
            æ¸¸æˆé…ç½®å­—å…¸
            
        è°ƒç”¨æ—¶æœº: åˆå§‹åŒ–æ¸¸æˆå¼•æ“æ—¶
        """
        return self.config["game"].copy()
        
    def get_logging_config(self) -> Dict[str, Any]:
        """
        è·å–æ—¥å¿—ç›¸å…³é…ç½®
        
        Returns:
            æ—¥å¿—é…ç½®å­—å…¸
            
        è°ƒç”¨æ—¶æœº: åˆå§‹åŒ–æ—¥å¿—ç³»ç»Ÿæ—¶
        """
        return self.config.get("logging", self._get_default_logging_config())
    
    def get_rag_config(self) -> Dict[str, Any]:
        """
        è·å–RAGç›¸å…³é…ç½®
        
        Returns:
            RAGé…ç½®å­—å…¸
            
        è°ƒç”¨æ—¶æœº: åˆå§‹åŒ–RAGç³»ç»Ÿæ—¶
        """
        return self.config.get("rag", {
            "enabled": False,
            "type": "lightrag", 
            "storage_path": "storage/conversations",
            "auto_create_session": True,
            "query_limit": 3,
            "context_turns": 5
        })
        
    def set_rag_enabled(self, enabled: bool) -> None:
        """
        å¯ç”¨æˆ–ç¦ç”¨RAGåŠŸèƒ½
        
        Args:
            enabled: æ˜¯å¦å¯ç”¨RAG
            
        è°ƒç”¨æ—¶æœº: ç”¨æˆ·åˆ‡æ¢RAGåŠŸèƒ½æ—¶
        """
        if "rag" not in self.config:
            self.config["rag"] = self.get_rag_config()
        self.config["rag"]["enabled"] = enabled
        self._save_config()
        print(f"RAGåŠŸèƒ½å·²{'å¯ç”¨' if enabled else 'ç¦ç”¨'}")
        
    def set_api_type(self, api_type: APIType) -> None:
        """
        è®¾ç½®APIç±»å‹
        
        Args:
            api_type: æ–°çš„APIç±»å‹
            
        è°ƒç”¨æ—¶æœº: ç”¨æˆ·åˆ‡æ¢AIåç«¯æ—¶
        """
        self.config["api"]["type"] = api_type.value
        self._save_config()
        print(f"å·²åˆ‡æ¢åˆ° {api_type.value}")
        
    def set_ollama_model(self, model_name: str) -> None:
        """
        è®¾ç½®Ollamaæ¨¡å‹
        
        Args:
            model_name: æ¨¡å‹åç§°
            
        è°ƒç”¨æ—¶æœº: ç”¨æˆ·åˆ‡æ¢Ollamaæ¨¡å‹æ—¶
        """
        if model_name not in self.config["ollama"]["available_models"]:
            print(f"è­¦å‘Š: {model_name} ä¸åœ¨æ¨èæ¨¡å‹åˆ—è¡¨ä¸­")
            
        self.config["ollama"]["model"] = model_name
        self._save_config()
        print(f"Ollamaæ¨¡å‹å·²è®¾ç½®ä¸º: {model_name}")
        
    def add_ollama_model(self, model_name: str) -> None:
        """
        æ·»åŠ æ–°çš„Ollamaæ¨¡å‹åˆ°å¯ç”¨åˆ—è¡¨
        
        Args:
            model_name: æ¨¡å‹åç§°
            
        è°ƒç”¨æ—¶æœº: ç”¨æˆ·å®‰è£…äº†æ–°æ¨¡å‹æ—¶
        """
        if model_name not in self.config["ollama"]["available_models"]:
            self.config["ollama"]["available_models"].append(model_name)
            self._save_config()
            print(f"å·²æ·»åŠ æ¨¡å‹: {model_name}")
        else:
            print(f"æ¨¡å‹ {model_name} å·²å­˜åœ¨")
            
    def display_config(self) -> None:
        """
        åœ¨æ§åˆ¶å°æ˜¾ç¤ºå½“å‰é…ç½®
        
        è°ƒç”¨æ—¶æœº: æ¸¸æˆå¼€å§‹æˆ–ç”¨æˆ·æŸ¥è¯¢é…ç½®æ—¶
        """
        api_type = self.get_api_type()
        api_config = self.get_api_config()
        
        print(f"\n=== å½“å‰é…ç½® ===")
        print(f"APIç±»å‹: {api_type.value}")
        print(f"æ¨¡å‹: {api_config['model']}")
        print(f"æœåŠ¡åœ°å€: {api_config['base_url']}")
        print(f"AIä¸Šä¸‹æ–‡é™åˆ¶: {api_config['context_limit']} tokens")
        
        if api_type == APIType.LM_STUDIO:
            print("æ³¨æ„: LM Studioä½¿ç”¨å½“å‰ç•Œé¢åŠ è½½çš„æ¨¡å‹")
            
        game_config = self.get_game_config()
        rag_config = self.get_rag_config()
        
        print(f"å³æ—¶ä¸Šä¸‹æ–‡: {game_config['context_history_limit']} è½®")
        
        # æ˜¾ç¤ºRAGçŠ¶æ€
        if rag_config.get('enabled'):
            print(f"ğŸ§  é•¿æœŸè®°å¿†: å·²å¯ç”¨ ({rag_config['type']})")
            print(f"   å­˜å‚¨è·¯å¾„: {rag_config['storage_path']}")
        else:
            print("ğŸ§  é•¿æœŸè®°å¿†: æœªå¯ç”¨")
            
        print("=" * 25)
        
    def interactive_setup(self) -> None:
        """
        äº¤äº’å¼é…ç½®è®¾ç½®
        
        è°ƒç”¨æ—¶æœº: é¦–æ¬¡ä½¿ç”¨æˆ–ç”¨æˆ·ä¸»åŠ¨é…ç½®æ—¶
        """
        print("=== AI-TRPG ç³»ç»Ÿé…ç½® ===")
        print("é€‰æ‹©AIåç«¯:")
        print("1. Ollama (æœ¬åœ°æ¨¡å‹æœåŠ¡ï¼Œæ”¯æŒå¤šæ¨¡å‹åˆ‡æ¢)")
        print("2. LM Studio (å›¾å½¢ç•Œé¢ç®¡ç†ï¼Œé«˜è´¨é‡æ¨¡å‹)")
        
        while True:
            choice = input("\nè¯·é€‰æ‹© (1-2): ").strip()
            
            if choice == "1":
                self._setup_ollama()
                break
            elif choice == "2":
                self._setup_lm_studio()
                break
            else:
                print("æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥1æˆ–2")
                
        # è®¾ç½®æ¸¸æˆå‚æ•°
        self._setup_game_config()
        
        print("\né…ç½®å®Œæˆï¼")
        self.display_config()
        
    def validate_config(self) -> List[str]:
        """
        éªŒè¯é…ç½®çš„æœ‰æ•ˆæ€§
        
        Returns:
            é…ç½®é”™è¯¯åˆ—è¡¨ï¼Œç©ºåˆ—è¡¨è¡¨ç¤ºé…ç½®æœ‰æ•ˆ
            
        è°ƒç”¨æ—¶æœº: ç³»ç»Ÿå¯åŠ¨å‰æˆ–é…ç½®æ›´æ–°å
        """
        errors = []
        
        # éªŒè¯APIé…ç½®
        api_type = self.get_api_type()
        api_config = self.config[api_type.value]
        
        if not api_config.get("base_url"):
            errors.append(f"{api_type.value} base_url ä¸èƒ½ä¸ºç©º")
            
        if api_config.get("context_limit", 0) <= 0:
            errors.append(f"{api_type.value} context_limit å¿…é¡»å¤§äº0")
            
        # éªŒè¯æ¸¸æˆé…ç½®
        game_config = self.config.get("game", {})
        if game_config.get("context_history_limit", 0) <= 0:
            errors.append("æ¸¸æˆé…ç½®ä¸­ context_history_limit å¿…é¡»å¤§äº0")
            
        return errors
        
    def reset_to_defaults(self) -> None:
        """
        é‡ç½®ä¸ºé»˜è®¤é…ç½®
        
        è°ƒç”¨æ—¶æœº: é…ç½®æŸåæˆ–ç”¨æˆ·è¦æ±‚é‡ç½®æ—¶
        """
        self.config = self._get_default_config()
        self._save_config()
        print("é…ç½®å·²é‡ç½®ä¸ºé»˜è®¤å€¼")
        
    def _load_config(self) -> Dict[str, Any]:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        try:
            # ç¡®ä¿é…ç½®ç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(self.config_file), exist_ok=True)
            
            with open(self.config_file, 'r', encoding='utf-8') as f:
                config = json.load(f)
                
            # éªŒè¯åŠ è½½çš„é…ç½®
            if self._is_valid_config_structure(config):
                return config
            else:
                print("é…ç½®æ–‡ä»¶ç»“æ„å¼‚å¸¸ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
                return self._get_default_config()
                
        except (FileNotFoundError, json.JSONDecodeError):
            print("é…ç½®æ–‡ä»¶ä¸å­˜åœ¨æˆ–æ ¼å¼é”™è¯¯ï¼Œåˆ›å»ºé»˜è®¤é…ç½®")
            default_config = self._get_default_config()
            self._save_config_dict(default_config)
            return default_config
            
    def _save_config(self) -> None:
        """ä¿å­˜å½“å‰é…ç½®åˆ°æ–‡ä»¶"""
        self._save_config_dict(self.config)
        
    def _save_config_dict(self, config_dict: Dict[str, Any]) -> None:
        """ä¿å­˜æŒ‡å®šé…ç½®å­—å…¸åˆ°æ–‡ä»¶"""
        os.makedirs(os.path.dirname(self.config_file), exist_ok=True)
        
        with open(self.config_file, 'w', encoding='utf-8') as f:
            json.dump(config_dict, f, indent=2, ensure_ascii=False)
            
    def _get_default_config(self) -> Dict[str, Any]:
        """è·å–é»˜è®¤é…ç½®"""
        return {
            "api": {
                "type": "ollama",
                "comment": "å¯é€‰: ollama æˆ– lm_studio"
            },
            "ollama": {
                "base_url": "http://localhost:11434/api/generate",
                "model": "qwen2.5:3b",
                "context_limit": 32000,
                "available_models": [
                    "qwen2.5:3b",
                    "qwen2.5:7b", 
                    "llama3.1:8b",
                    "gemma2:9b"
                ]
            },
            "lm_studio": {
                "base_url": "http://localhost:1234/v1/chat/completions",
                "model": "current_loaded",
                "context_limit": 128000,
                "note": "æ¨¡å‹åç§°æ— å…³ç´§è¦ï¼ŒLM Studioè‡ªåŠ¨ä½¿ç”¨å½“å‰åŠ è½½çš„æ¨¡å‹",
                "recommended_models": [
                    "hermes-3-llama-3.1-8b",
                    "hermes-3-llama-3.1-70b", 
                    "nous-hermes-2-mixtral-8x7b",
                    "qwen2.5-coder-32b-instruct"
                ]
            },
            "game": {
                "context_history_limit": 3,
                "auto_adjust_context": True,
                "max_turns": 1000
            },
            "rag": {
                "enabled": False,
                "type": "lightrag",
                "storage_path": "storage/conversations",
                "auto_create_session": True,
                "query_limit": 3,
                "context_turns": 5
            },
            "logging": {
                "log_file": "logs/trpg_game.log",
                "log_level": "INFO",
                "enable_console_output": True
            }
        }
        
    def _get_default_logging_config(self) -> Dict[str, Any]:
        """è·å–é»˜è®¤æ—¥å¿—é…ç½®"""
        return {
            "log_file": "logs/trpg_game.log",
            "log_level": "INFO", 
            "enable_console_output": True
        }
        
    def _is_valid_config_structure(self, config: Dict[str, Any]) -> bool:
        """æ£€æŸ¥é…ç½®ç»“æ„æ˜¯å¦æœ‰æ•ˆ"""
        required_keys = ["api", "ollama", "lm_studio", "game"]
        return all(key in config for key in required_keys)
        
    def _setup_ollama(self) -> None:
        """è®¾ç½®Ollamaé…ç½®"""
        self.set_api_type(APIType.OLLAMA)
        
        available_models = self.config["ollama"]["available_models"]
        current_model = self.config["ollama"]["model"]
        
        print(f"\nå¯ç”¨æ¨¡å‹: {', '.join(available_models)}")
        print(f"å½“å‰æ¨¡å‹: {current_model}")
        
        new_model = input("é€‰æ‹©æ–°æ¨¡å‹ (å›è½¦è·³è¿‡): ").strip()
        if new_model:
            self.set_ollama_model(new_model)
            
    def _setup_lm_studio(self) -> None:
        """è®¾ç½®LM Studioé…ç½®"""
        self.set_api_type(APIType.LM_STUDIO)
        
        recommended = self.config["lm_studio"]["recommended_models"]
        print(f"\næ¨èæ¨¡å‹: {', '.join(recommended[:3])}...")
        print("è¯·ç¡®ä¿LM Studioå·²å¯åŠ¨å¹¶åŠ è½½äº†æ¨¡å‹")
        
        # å¯é€‰æ‹©æ€§è®¾ç½®ç«¯å£
        current_url = self.config["lm_studio"]["base_url"]
        print(f"å½“å‰æœåŠ¡åœ°å€: {current_url}")
        
        new_url = input("è‡ªå®šä¹‰æœåŠ¡åœ°å€ (å›è½¦è·³è¿‡): ").strip()
        if new_url:
            self.config["lm_studio"]["base_url"] = new_url
            self._save_config()
            
    def _setup_game_config(self) -> None:
        """è®¾ç½®æ¸¸æˆé…ç½®"""
        print("\n=== æ¸¸æˆé…ç½® ===")
        
        current_limit = self.config["game"]["context_history_limit"]
        print(f"å½“å‰å†å²è®°å½•é™åˆ¶: {current_limit}")
        
        new_limit = input("è®¾ç½®å†å²è®°å½•æ•°é‡ (å›è½¦è·³è¿‡): ").strip()
        if new_limit and new_limit.isdigit():
            self.config["game"]["context_history_limit"] = int(new_limit)
            self._save_config()
            print(f"å·²è®¾ç½®ä¸º: {new_limit}")
            
    def get_log_file_path(self) -> str:
        """è·å–æ—¥å¿—æ–‡ä»¶è·¯å¾„"""
        return self.config.get("logging", {}).get("log_file", "logs/trpg_game.log")